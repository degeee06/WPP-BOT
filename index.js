import express from "express";
import bodyParser from "body-parser";
import fetch from "node-fetch";
import twilio from "twilio";

const app = express();
app.use(bodyParser.urlencoded({ extended: false }));

// OpenRouter config
const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;
const OPENROUTER_ENDPOINT = "https://openrouter.ai/api/v1/chat/completions";
const MODEL_NAME = "deepseek/chat-v3-0324:free"; // exemplo de modelo grÃ¡tis em 2025

// Respostas fixas (fallback se nÃ£o usar IA)
const responses = {
  "produto": "Temos diversos produtos disponÃ­veis. Quer ver nosso catÃ¡logo?",
  "catalogo": "Aqui estÃ¡ nosso catÃ¡logo: [link do catÃ¡logo]",
  "preÃ§o": "Os preÃ§os variam conforme o produto. Qual item vocÃª quer saber?",
  "pagamento": "Aceitamos PIX, cartÃ£o e boleto. Deseja prosseguir?",
  "default": "Desculpe, nÃ£o entendi. Vou consultar a IA para te ajudar..."
};

// FunÃ§Ã£o para respostas fixas
function getResponse(msg) {
  msg = msg.toLowerCase();
  if (msg.includes("produto")) return responses.produto;
  if (msg.includes("catalogo")) return responses.catalogo;
  if (msg.includes("preÃ§o") || msg.includes("valor")) return responses.preÃ§o;
  if (msg.includes("pagamento") || msg.includes("pix")) return responses.pagamento;
  return null; // se nÃ£o achou, cai na IA
}

// FunÃ§Ã£o para consultar IA via OpenRouter
async function queryLLM(userMessage) {
  try {
    const res = await fetch(OPENROUTER_ENDPOINT, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${OPENROUTER_API_KEY}`
      },
      body: JSON.stringify({
        model: MODEL_NAME,
        messages: [{ role: "user", content: userMessage }]
      })
    });

    const data = await res.json();
    if (!res.ok) {
      console.error("Erro LLM:", data);
      return "âš ï¸ Houve um erro ao consultar a IA.";
    }

    return data.choices[0].message.content;
  } catch (err) {
    console.error("Falha ao chamar IA:", err);
    return "âš ï¸ NÃ£o consegui acessar a IA agora.";
  }
}

// Endpoint Twilio â†’ WhatsApp
app.post("/whatsapp", async (req, res) => {
  const incomingMsg = req.body.Body || "";
  
  // Primeiro tenta resposta fixa
  let reply = getResponse(incomingMsg);

  // Se nÃ£o achou, consulta IA
  if (!reply) {
    reply = await queryLLM(incomingMsg);
  }

  const twiml = new twilio.twiml.MessagingResponse();
  twiml.message(reply);

  res.writeHead(200, { "Content-Type": "text/xml" });
  res.end(twiml.toString());
});

// Inicia servidor
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`ðŸ¤– Bot rodando na porta ${PORT}`));
